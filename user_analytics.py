from load_data_from_db import load_data_for_analytics
import asyncio
import pandas as pd
import matplotlib
matplotlib.use('Agg') # <-- Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð½ÐµÑ–Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹ Ð±ÐµÐºÐµÐ½Ð´
import matplotlib.pyplot as plt # <-- Ð†Ð¼Ð¿Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ pyplot ÐŸÐ†Ð¡Ð›Ð¯ Ð²ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð±ÐµÐºÐµÐ½Ð´Ñƒ
import numpy as np


async def prepare_aggregate_data_by_period_and_draw_analytic_for_user(user_id, start_date, end_date):
    """Loads user analytics data, enriches it with error statistics, 
    calculates session-based metrics, and returns a merged DataFrame."""

    # ðŸ”¹ Load data for a specific user (replace this with a loop for all users if needed)
    loop= asyncio.get_running_loop()
    dfs = await loop.run_in_executor(
        None,
        load_data_for_analytics,
        user_id, start_date, end_date
        )

    all_user_sentences = dfs["sentences"].copy()
    all_user_sentences.rename(columns={"id": "sentence_id"}, inplace=True)
    not_succeded_sentences = dfs["not_succesed_attempts"].copy()
    not_succeded_sentences.rename(columns={
        "attempt":"attempt_not_succeded"
    }, inplace=True)

    successful_user_translation = dfs["success"].copy()
    
    time_costs_for_user = dfs["progress"]
    still_mistakes = dfs["mistakes"].copy()

    # ðŸ”¹ Rename columns for joining (Ñ‚Ð°Ðº ÐºÐ°Ðº Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ detailed_mistakes ÐŸÐ¾Ð´ sentence_id ÐÐ° ÑÐ°Ð¼Ð¾Ð¼ Ð´ÐµÐ»Ðµ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ id_for_mistake_table)
    still_mistakes.rename(columns={
        "sentence_id": "id_for_mistake_table",
        "score": "current_score"
    }, inplace=True)

    successful_user_translation.rename(columns={
        "sentence_id": "id_for_mistake_table"
    }, inplace=True)   

    
    # ðŸ”¹ Align date formats for join (set time to 00:00:00)
    #still_mistakes["added_data"] = pd.to_datetime(still_mistakes["added_data"]).dt.floor("D")
    all_user_sentences["date"] = pd.to_datetime(all_user_sentences["date"]).dt.floor("D")
    

    successful_user_translation.rename(columns={
        "date": "date_of_success"
    }, inplace=True)
    successful_user_translation["date_of_success"] = pd.to_datetime(successful_user_translation["date_of_success"].dt.floor("D"))
    
    # ðŸ”¹ Merge base user sentence data
    ds_for_plot = all_user_sentences.merge(
        successful_user_translation,
        on="id_for_mistake_table", 
        how="left"
    )

    ds_for_plot = ds_for_plot.merge(
        time_costs_for_user[["session_id", "username", "start_time", "end_time"]],
        on="session_id", 
        how="left"
        )

    # ðŸ”¹ Rename, compute durations
    ds_for_plot["start_session"] = ds_for_plot["start_time"]
    ds_for_plot["end_session"] = ds_for_plot["end_time"]
    ds_for_plot.drop(["start_time", "end_time"], axis="columns", inplace=True)

    ds_for_plot["session_duration"] = (
        ds_for_plot["end_session"] - ds_for_plot["start_session"]
    ).dt.total_seconds()

    # groupby("date"): Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÑ‚ Ð²ÑÐµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð¿Ð¾ Ð´Ð°Ñ‚Ðµ
    # ["sentence_id"]: Ð²Ñ‹Ð±Ð¸Ñ€Ð°ÐµÑ‚ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ sentence_id Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ðµ
    # .count(): ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð½ÐµÐ¿ÑƒÑÑ‚Ñ‹Ñ… sentence_id Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ðµ
    # transform("count"): Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¶Ðµ ÑÑ‚Ñ€Ð¾Ðº, ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð² Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð¼ DataFrame, Ñ Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ñ‹Ð¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÐµÐ¼ Ð´Ð»Ñ Ð²ÑÐµÑ… ÑÑ‚Ñ€Ð¾Ðº Ñ‚Ð¾Ð¹ Ð¶Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹
    # count() Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ð´Ð½Ñƒ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ð½Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: date | count)
    # but transform("count") Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ð´Ð½Ñƒ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ð½Ð° ÐºÐ°Ð¶Ð´ÑƒÑŽ Ð·Ð°Ð¿Ð¸ÑÑŒ, Ð¸ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÑÑ‚Ð¾ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ DataFrame â€” Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð´Ð»Ñ Ð´ÐµÐ»ÐµÐ½Ð¸Ñ
    ds_for_plot["sentences_in_session"] = ds_for_plot.groupby(["date", "session_id"])["sentence_id"].transform("count")

    ds_for_plot["avg_min_sentence_session"] = round(
        ((ds_for_plot["session_duration"] / ds_for_plot["sentences_in_session"]) / 60), 2
    )

    # ðŸ”¹ Rename column for clarity
    ds_for_plot.rename(
        columns={
            "attempt": "attempt_successed",
            "score": "score_successed"}, 
        inplace=True
        )

    ds_for_plot["sentences_in_day"] = ds_for_plot.groupby("date")["sentence_id"].transform("count")
    session_durations = ds_for_plot.drop_duplicates("session_id")[["date", "session_id", "session_duration"]]
    total_time_per_day = session_durations.groupby("date")["session_duration"].sum()
    
    ds_for_plot = ds_for_plot.merge(
    total_time_per_day.rename("spent_time_per_day"),
    on="date",
    how="left"
    )

    ds_for_plot["avg_min_sentence_day"] = round(
        ((ds_for_plot["spent_time_per_day"] / ds_for_plot["sentences_in_day"]) / 60), 2
    )

    ds_for_plot = ds_for_plot.merge(
    not_succeded_sentences,
    on=["id_for_mistake_table", "user_id"],
    how="left"
    )

    # ðŸ”¹ Merge with mistake statistics
    ds_for_plot = ds_for_plot.merge(
        still_mistakes,
        on=["id_for_mistake_table"],
        how="left"
    )

    # ðŸ”¹ Optional: add flag whether the sentence had a mistake
    ds_for_plot["user_stil_has_mistake"] = ds_for_plot["attempt_not_succeded"].notna()


    # ðŸ”¹ Export to Excel (optional)
    ds_for_plot.to_excel("test_ds.xlsx", index=False)

    return ds_for_plot

async def aggregate_data_for_charts(df: pd.DataFrame, period: str="week") -> pd.DataFrame:
    """
    ÐÐ³Ñ€ÐµÐ³ÑƒÑ” Ð´Ð°Ð½Ñ– Ð´Ð»Ñ Ð¿Ð¾Ð±ÑƒÐ´Ð¾Ð²Ð¸ Ð³Ñ€Ð°Ñ„Ñ–ÐºÑ–Ð² Ð·Ð³Ñ–Ð´Ð½Ð¾ Ð· Ð½Ð°Ð´Ð°Ð½Ð¸Ð¼Ð¸ Ð¼Ð°ÐºÐµÑ‚Ð°Ð¼Ð¸.
    Ð’Ñ€Ð°Ñ…Ð¾Ð²ÑƒÑ” ÑƒÐ½Ñ–ÐºÐ°Ð»ÑŒÐ½Ñ–ÑÑ‚ÑŒ Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ñ–Ð² Ð·Ð° Ð¿Ð°Ñ€Ð¾ÑŽ (session_id, id_for_mistake_table).
    
    Args:
        df (pd.DataFrame): Ð’Ñ…Ñ–Ð´Ð½Ð¸Ð¹ DataFrame (ds_for_plot).
        period (str): ÐŸÐµÑ€Ñ–Ð¾Ð´ Ð´Ð»Ñ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ñ–Ñ—: 'day', 'week', 'month', 'quarter', 'year'.

    Returns:
        pd.DataFrame: DataFrame Ð· ÑƒÑÑ–Ð¼Ð° Ð¿Ð¾ÐºÐ°Ð·Ð½Ð¸ÐºÐ°Ð¼Ð¸, Ð½ÐµÐ¾Ð±Ñ…Ñ–Ð´Ð½Ð¸Ð¼Ð¸ Ð´Ð»Ñ Ð³Ñ€Ð°Ñ„Ñ–ÐºÑ–Ð².
    """

    # 1. Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÑ”Ð¼Ð¾ "Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð¸Ð¹" DataFrame, Ð²Ð¸Ð´Ð°Ð»ÑÑŽÑ‡Ð¸ Ð´ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ð¸ ÑÐ¿Ñ€Ð¾Ð± Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ñƒ
    # Ð¦Ðµ ÐºÐ»ÑŽÑ‡Ð¾Ð²Ð¸Ð¹ ÐºÑ€Ð¾Ðº, ÑÐºÐ¸Ð¹ Ñ€ÐµÐ°Ð»Ñ–Ð·ÑƒÑ” Ð²Ð°ÑˆÑƒ Ð»Ð¾Ð³Ñ–ÐºÑƒ Ð¿Ñ–Ð´Ñ€Ð°Ñ…ÑƒÐ½ÐºÑƒ
    cleaned_df = df.drop_duplicates(subset=['session_id', 'id_for_mistake_table']).copy()
    cleaned_df['date'] = pd.to_datetime(cleaned_df['date'])

    # 2. Ð”Ð¾Ð´Ð°Ñ”Ð¼Ð¾ Ð´Ð¾Ð¿Ð¾Ð¼Ñ–Ð¶Ð½Ñ– ÑÑ‚Ð¾Ð²Ð¿Ñ†Ñ– Ð´Ð»Ñ Ð·Ñ€ÑƒÑ‡Ð½Ð¾ÑÑ‚Ñ– Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ñ–Ñ—
    cleaned_df['is_successful'] = cleaned_df['score_successed'] >= 80
    cleaned_df['is_unsuccessful'] = cleaned_df['current_score'] > 0
    total_unsuccessful = cleaned_df['is_unsuccessful'].sum()
    print(total_unsuccessful)
    cleaned_df['attempt_1_success'] = (cleaned_df['is_successful']) & (cleaned_df['attempt_successed'] == 1)
    cleaned_df['attempt_2_success'] = (cleaned_df['is_successful']) & (cleaned_df['attempt_successed'] == 2)
    cleaned_df['attempt_3plus_success'] = (cleaned_df['is_successful']) & (cleaned_df['attempt_successed'] >= 3)
    
    # Ð¡Ð»Ð¾Ð²Ð½Ð¸Ðº Ð´Ð»Ñ Ð³Ð½ÑƒÑ‡ÐºÐ¾Ð³Ð¾ Ð²Ð¸Ð±Ð¾Ñ€Ñƒ Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ Ð³Ñ€ÑƒÐ¿ÑƒÐ²Ð°Ð½Ð½Ñ
    period_mappers = {
        "day": cleaned_df["date"].dt.to_period("D"),
        "week": cleaned_df["date"].dt.to_period("W"),
        "month": cleaned_df["date"].dt.to_period("M"),
        "quarter": cleaned_df["date"].dt.to_period("Q"),
        "year": cleaned_df["date"].dt.to_period("Y")
    }
    if period not in period_mappers:
        raise ValueError("Used incorrected grouped period. Please use 'day', 'week', 'month', 'quarter' Ð°Ð±Ð¾ 'year'.")
    
    grouper = period_mappers[period]
    # 3. ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ñ–Ñ Ð¿Ð¾ÐºÐ°Ð·Ð½Ð¸ÐºÑ–Ð² Ð´Ð»Ñ Ð³Ñ€Ð°Ñ„Ñ–ÐºÑ–Ð² Ð· "Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð¸Ñ…" Ð´Ð°Ð½Ð¸Ñ…
    sentence_agg = cleaned_df.groupby(grouper).agg(
        # ÐŸÐ¾ÐºÐ°Ð·Ð½Ð¸ÐºÐ¸ Ð´Ð»Ñ Ð“Ñ€Ð°Ñ„Ñ–ÐºÑƒ 1
        total_translations = ("session_id", "count"),
        successful_translations = ('is_successful', 'sum'),
        unsuccessful_translations = ('is_unsuccessful', 'sum'),
        # ÐŸÐ¾ÐºÐ°Ð·Ð½Ð¸ÐºÐ¸ Ð´Ð»Ñ Ð“Ñ€Ð°Ñ„Ñ–ÐºÑƒ 2
        success_on_1st_attempt=('attempt_1_success', 'sum'),
        success_on_2nd_attempt=('attempt_2_success', 'sum'),
        success_on_3plus_attempt=('attempt_3plus_success', 'sum'),
    )


    # 4. ÐžÐºÑ€ÐµÐ¼Ð¾ Ð°Ð³Ñ€ÐµÐ³ÑƒÑ”Ð¼Ð¾ Ñ‡Ð°Ñ, Ñ‰Ð¾Ð± ÑƒÐ½Ð¸ÐºÐ½ÑƒÑ‚Ð¸ Ð¿Ð¾Ð´Ð²Ñ–Ð¹Ð½Ð¾Ð³Ð¾ Ð¿Ñ–Ð´Ñ€Ð°Ñ…ÑƒÐ½ÐºÑƒ
    session_unique_df = df.drop_duplicates(subset=['date', 'session_id'])
    session_agg = session_unique_df.groupby(grouper).agg(
        total_time_spent_sec = ('session_duration', 'sum')
    )

    # 5. ÐžÐ±'Ñ”Ð´Ð½ÑƒÑ”Ð¼Ð¾ Ð²ÑÐµ Ð² Ð¾Ð´Ð½Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†ÑŽ
    df_grouped = pd.concat([sentence_agg, session_agg], axis=1).fillna(0)

    # 6. Ð Ð¾Ð·Ñ€Ð°Ñ…Ð¾Ð²ÑƒÑ”Ð¼Ð¾ Ñ„Ñ–Ð½Ð°Ð»ÑŒÐ½Ñ– Ð²Ñ–Ð´Ð½Ð¾ÑÐ½Ñ– Ð¿Ð¾ÐºÐ°Ð·Ð½Ð¸ÐºÐ¸ (Ð´Ð¾Ð»Ñ–, ÑÐµÑ€ÐµÐ´Ð½Ñ–Ð¹ Ñ‡Ð°Ñ)
    df_grouped['total_time_spent_min'] = round(df_grouped['total_time_spent_sec']/ 60, 2)
    df_grouped['avg_min_per_translation'] = df_grouped.apply(
        lambda row: round(row["total_time_spent_min"] / row["total_translations"], 2) if row["total_translations"] > 0 else 0,
        axis=1
    )

    # Ð Ð¾Ð·Ñ€Ð°Ñ…ÑƒÐ½Ð¾Ðº Ð´Ð¾Ð»ÐµÐ¹ Ð´Ð»Ñ Ð“Ñ€Ð°Ñ„Ñ–ÐºÑƒ 1
    df_grouped['share_successful'] = df_grouped.apply(
        lambda row: round(row["successful_translations"]/ row["total_translations"] * 100, 1) if row["successful_translations"] > 0 else 0,
        axis=1
    )
    df_grouped['share_unsuccessful'] = 100 - df_grouped['share_successful']

    # Ð’Ð¸Ð´Ð°Ð»ÑÑ”Ð¼Ð¾ Ð½ÐµÐ¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ð¸Ð¹ ÑÑ‚Ð¾Ð²Ð¿ÐµÑ†ÑŒ
    df_grouped.drop(columns=['total_time_spent_sec'], inplace=True)

    df_grouped.to_excel("grouped_ds.xlsx", index=True)

    return df_grouped


def plot_user_analytics(ax, df, title, chart_type='time_and_success'):
    """
    ÐœÐ°Ð»ÑŽÑ” Ð¾Ð´Ð¸Ð½ Ð°Ð½Ð°Ð»Ñ–Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ð³Ñ€Ð°Ñ„Ñ–Ðº Ð½Ð° Ð²ÐºÐ°Ð·Ð°Ð½Ñ–Ð¹ Ð¾ÑÑ– (ax).

    Args:
        ax (matplotlib.axes.Axes): Ð’Ñ–ÑÑŒ, Ð½Ð° ÑÐºÑ–Ð¹ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ð¾ Ð¼Ð°Ð»ÑŽÐ²Ð°Ñ‚Ð¸.
        df (pd.DataFrame): ÐÐ³Ñ€ÐµÐ³Ð¾Ð²Ð°Ð½Ñ– Ð´Ð°Ð½Ñ– Ð´Ð»Ñ Ð¿Ð¾Ð±ÑƒÐ´Ð¾Ð²Ð¸.
        title (str): Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð´Ð»Ñ Ð³Ñ€Ð°Ñ„Ñ–ÐºÐ°.
        chart_type (str): Ð¢Ð¸Ð¿ Ð³Ñ€Ð°Ñ„Ñ–ÐºÐ° ('time_and_success' Ð°Ð±Ð¾ 'attempts').
    """
    # Ð“Ð¾Ñ‚ÑƒÑ”Ð¼Ð¾ Ð´Ð°Ð½Ñ– Ð´Ð»Ñ Ð¾ÑÑ– X
    x_labels = df.index.astype(str)
    x = np.arange(len(x_labels)) 

    if chart_type == 'time_and_success':
        # --- Ð“Ñ€Ð°Ñ„Ñ–Ðº 1: Ð”Ð¾Ð»Ñ ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¸Ñ…/Ð½ÐµÑƒÑÐ¿Ñ–ÑˆÐ½Ð¸Ñ… Ñ– Ñ‡Ð°Ñ ---

        # ÐœÐ°Ð»ÑŽÑ”Ð¼Ð¾ ÑÑ‚Ð¾Ð²Ð¿Ñ‡Ð°ÑÑ‚Ñƒ Ð´Ñ–Ð°Ð³Ñ€Ð°Ð¼Ñƒ
        ax.bar(x, df['successful_translations'], width=0.6, label="Successful(>=80)", color="g")
        ax.bar(x, df['unsuccessful_translations'], width=0.6, bottom=df['successful_translations'], label="Unsuccessful(<80)", color="r")
        ax.set_ylabel("Number of translations")
        ax.legend(loc="upper left")

        # Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÑ”Ð¼Ð¾ Ð´Ñ€ÑƒÐ³Ñƒ Ð²Ñ–ÑÑŒ Y Ð´Ð»Ñ Ð³Ñ€Ð°Ñ„Ñ–ÐºÐ° Ñ‡Ð°ÑÑƒ
        ax2 = ax.twinx()
        ax2.plot(x, df['avg_min_per_translation'], color="b", marker='o', linestyle='--', label= "Average time (min) per each translation")
        ax2.set_ylabel("Minutes", color="b")
        ax2.tick_params(axis="y", labelcolor="b")
        ax2.legend(loc="upper right")
    
    elif chart_type == "attempts":
        # --- Ð“Ñ€Ð°Ñ„Ñ–Ðº 2: ÐÐ½Ð°Ð»Ñ–Ð· Ð·Ð° ÑÐ¿Ñ€Ð¾Ð±Ð°Ð¼Ð¸ ---
        ax.bar(x, df['success_on_1st_attempt'], width=0.6, label="Success from the 1 try", color='#2ca02c')
        ax.bar(x, df['success_on_2nd_attempt'], width=0.6, label="Success from the 2 try", 
                bottom=df['success_on_1st_attempt'],color='#ff7f0e')
        bottom_3 = df['success_on_1st_attempt'] +df['success_on_2nd_attempt']
        ax.bar(x, df['success_on_3plus_attempt'], width=0.6, bottom=bottom_3,
            label='Success from the 3 try', color='#1f77b4')
        bottom_4 = bottom_3 + df['success_on_3plus_attempt']
        ax.bar(x, df['unsuccessful_translations'], width=0.6, bottom=bottom_4,
            label='ÐÐµÑƒÑÐ¿Ñ–ÑˆÐ½Ñ–', color='#d62728') # Ñ‡ÐµÑ€Ð²Ð¾Ð½Ð¸Ð¹
        
        ax.set_ylabel("Number of translations")
        ax.legend(loc="best")

    ax.set_title(title, fontsize=14)
    ax.set_xticks(x)
    ax.set_xticklabels(x_labels, rotation=45, ha="right")
    ax.grid(True,axis="x", linestyle="--", alpha=0.7)
    

async def create_analytics_figure_async(daily_data, weekly_data, user_id):
    """
    Async shell for the creation of the bar-chart
    """
    loop = asyncio.get_running_loop()
    
    fig, axes = plt.subplots(2,1, figsize=(14,12))

    await loop.run_in_executor(
        None,
        plot_user_analytics,
        axes[0],
        daily_data.tail(7),
        "Daily Analytics: Time and Success",
        'time_and_success'
    )

    await loop.run_in_executor(
        None,
        plot_user_analytics,
        axes[1],
        weekly_data.tail(4),
        "Weekly Analytics: Tries",
        "attempts"
    )

            
    # Ð”Ð¾Ð´Ð°Ñ”Ð¼Ð¾ Ð·Ð°Ð³Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
    fig.suptitle(f"The whole Analytics for the user {user_id}", fontsize=16)

    # Ð Ð¾Ð±Ð¸Ð¼Ð¾ Ð²Ð¸Ð³Ð»ÑÐ´ ÐºÐ¾Ð¼Ð¿Ð°ÐºÑ‚Ð½Ñ–ÑˆÐ¸Ð¼
    plt.tight_layout(rect=[0, 0, 1, 0.96]) # Ð—Ð°Ð»Ð¸ÑˆÐ°Ñ”Ð¼Ð¾ Ð¼Ñ–ÑÑ†Ðµ Ð´Ð»Ñ suptitle

    #save in file to send it to telegram
    figure_path = f"analytics_{user_id}.png"
    fig.savefig(figure_path)
    plt.close(fig)

    return figure_path




