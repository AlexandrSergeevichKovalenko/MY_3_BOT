from load_data_from_db import load_data_for_analytics
import asyncio
import pandas as pd
import matplotlib
matplotlib.use('Agg') # <-- –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –Ω–µ—ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π –±–µ–∫–µ–Ω–¥
import matplotlib.pyplot as plt # <-- –Ü–º–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ pyplot –ü–Ü–°–õ–Ø –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –±–µ–∫–µ–Ω–¥—É
import numpy as np


async def prepare_aggregate_data_by_period_and_draw_analytic_for_user(user_id, start_date, end_date):
    """Loads user analytics data, enriches it with error statistics, 
    calculates session-based metrics, and returns a merged DataFrame."""

    # üîπ Load data for a specific user (replace this with a loop for all users if needed)
    loop= asyncio.get_running_loop()
    dfs = await loop.run_in_executor(
        None,
        load_data_for_analytics,
        user_id, start_date, end_date
        )

    all_user_sentences = dfs["sentences"].copy()
    all_user_sentences.rename(columns={"id": "sentence_id"}, inplace=True)
    not_succeded_sentences = dfs["not_succesed_attempts"].copy()
    not_succeded_sentences.rename(columns={
        "attempt":"attempt_not_succeded"
    }, inplace=True)

    successful_user_translation = dfs["success"].copy()
    
    time_costs_for_user = dfs["progress"]
    still_mistakes = dfs["mistakes"].copy()

    # üîπ Rename columns for joining (—Ç–∞–∫ –∫–∞–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ detailed_mistakes –ü–æ–¥ sentence_id –ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è id_for_mistake_table)
    still_mistakes.rename(columns={
        "sentence_id": "id_for_mistake_table",
        "score": "current_score"
    }, inplace=True)

    successful_user_translation.rename(columns={
        "sentence_id": "id_for_mistake_table"
    }, inplace=True)   

    
    # üîπ Align date formats for join (set time to 00:00:00)
    #still_mistakes["added_data"] = pd.to_datetime(still_mistakes["added_data"]).dt.floor("D")
    all_user_sentences["date"] = pd.to_datetime(all_user_sentences["date"]).dt.floor("D")
    

    successful_user_translation.rename(columns={
        "date": "date_of_success"
    }, inplace=True)
    successful_user_translation["date_of_success"] = pd.to_datetime(successful_user_translation["date_of_success"].dt.floor("D"))
    
    # üîπ Merge base user sentence data
    ds_for_plot = all_user_sentences.merge(
        successful_user_translation,
        on="id_for_mistake_table", 
        how="left"
    )

    ds_for_plot = ds_for_plot.merge(
        time_costs_for_user[["session_id", "username", "start_time", "end_time"]],
        on="session_id", 
        how="left"
        )

    # üîπ Rename, compute durations
    ds_for_plot["start_session"] = ds_for_plot["start_time"]
    ds_for_plot["end_session"] = ds_for_plot["end_time"]
    ds_for_plot.drop(["start_time", "end_time"], axis="columns", inplace=True)

    ds_for_plot["session_duration"] = (
        ds_for_plot["end_session"] - ds_for_plot["start_session"]
    ).dt.total_seconds()

    # groupby("date"): –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ –¥–∞—Ç–µ
    # ["sentence_id"]: –≤—ã–±–∏—Ä–∞–µ—Ç –∫–æ–ª–æ–Ω–∫—É sentence_id –≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ
    # .count(): —Å—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—É—Å—Ç—ã—Ö sentence_id –≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ
    # transform("count"): –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–æ–ª—å–∫–æ –∂–µ —Å—Ç—Ä–æ–∫, —Å–∫–æ–ª—å–∫–æ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º DataFrame, —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫ —Ç–æ–π –∂–µ –≥—Ä—É–ø–ø—ã
    # count() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –Ω–∞ –≥—Ä—É–ø–ø—É (–Ω–∞–ø—Ä–∏–º–µ—Ä: date | count)
    # but transform("count") –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –Ω–∞ –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å, –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ DataFrame ‚Äî –Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –¥–µ–ª–µ–Ω–∏—è
    ds_for_plot["sentences_in_session"] = ds_for_plot.groupby(["date", "session_id"])["sentence_id"].transform("count")

    ds_for_plot["avg_min_sentence_session"] = round(
        ((ds_for_plot["session_duration"] / ds_for_plot["sentences_in_session"]) / 60), 2
    )

    # üîπ Rename column for clarity
    ds_for_plot.rename(
        columns={
            "attempt": "attempt_successed",
            "score": "score_successed"}, 
        inplace=True
        )

    ds_for_plot["sentences_in_day"] = ds_for_plot.groupby("date")["sentence_id"].transform("count")
    session_durations = ds_for_plot.drop_duplicates("session_id")[["date", "session_id", "session_duration"]]
    total_time_per_day = session_durations.groupby("date")["session_duration"].sum()
    
    ds_for_plot = ds_for_plot.merge(
    total_time_per_day.rename("spent_time_per_day"),
    on="date",
    how="left"
    )

    ds_for_plot["avg_min_sentence_day"] = round(
        ((ds_for_plot["spent_time_per_day"] / ds_for_plot["sentences_in_day"]) / 60), 2
    )

    ds_for_plot = ds_for_plot.merge(
    not_succeded_sentences,
    on=["id_for_mistake_table", "user_id"],
    how="left"
    )

    # üîπ Merge with mistake statistics
    ds_for_plot = ds_for_plot.merge(
        still_mistakes,
        on=["id_for_mistake_table"],
        how="left"
    )

    # üîπ Optional: add flag whether the sentence had a mistake
    ds_for_plot["user_stil_has_mistake"] = ds_for_plot["attempt_not_succeded"].notna()


    # üîπ Export to Excel (optional)
    ds_for_plot.to_excel("test_ds.xlsx", index=False)

    return ds_for_plot

async def aggregate_data_for_charts(df: pd.DataFrame, period: str="week") -> pd.DataFrame:
    """
    –ê–≥—Ä–µ–≥—É—î –¥–∞–Ω—ñ –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏ –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –∑–≥—ñ–¥–Ω–æ –∑ –Ω–∞–¥–∞–Ω–∏–º–∏ –º–∞–∫–µ—Ç–∞–º–∏.
    –í—Ä–∞—Ö–æ–≤—É—î —É–Ω—ñ–∫–∞–ª—å–Ω—ñ—Å—Ç—å –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤ –∑–∞ –ø–∞—Ä–æ—é (session_id, id_for_mistake_table).
    
    Args:
        df (pd.DataFrame): –í—Ö—ñ–¥–Ω–∏–π DataFrame (ds_for_plot).
        period (str): –ü–µ—Ä—ñ–æ–¥ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü—ñ—ó: 'day', 'week', 'month', 'quarter', 'year'.

    Returns:
        pd.DataFrame: DataFrame –∑ —É—Å—ñ–º–∞ –ø–æ–∫–∞–∑–Ω–∏–∫–∞–º–∏, –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏–º–∏ –¥–ª—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤.
    """

    # 1. –°—Ç–≤–æ—Ä—é—î–º–æ "–æ—á–∏—â–µ–Ω–∏–π" DataFrame, –≤–∏–¥–∞–ª—è—é—á–∏ –¥—É–±–ª—ñ–∫–∞—Ç–∏ —Å–ø—Ä–æ–± –ø–µ—Ä–µ–∫–ª–∞–¥—É
    # –¶–µ –∫–ª—é—á–æ–≤–∏–π –∫—Ä–æ–∫, —è–∫–∏–π —Ä–µ–∞–ª—ñ–∑—É—î –≤–∞—à—É –ª–æ–≥—ñ–∫—É –ø—ñ–¥—Ä–∞—Ö—É–Ω–∫—É
    cleaned_df = df.drop_duplicates(subset=['session_id', 'id_for_mistake_table']).copy()
    cleaned_df['date'] = pd.to_datetime(cleaned_df['date'])

    # 2. –î–æ–¥–∞—î–º–æ –¥–æ–ø–æ–º—ñ–∂–Ω—ñ —Å—Ç–æ–≤–ø—Ü—ñ –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ –∞–≥—Ä–µ–≥–∞—Ü—ñ—ó
    cleaned_df['is_successful'] = cleaned_df['score_successed'] >= 80
    cleaned_df['is_unsuccessful'] = cleaned_df['current_score'] > 0
    total_unsuccessful = cleaned_df['is_unsuccessful'].sum()
    print(total_unsuccessful)
    cleaned_df['attempt_1_success'] = (cleaned_df['is_successful']) & (cleaned_df['attempt_successed'] == 1)
    cleaned_df['attempt_2_success'] = (cleaned_df['is_successful']) & (cleaned_df['attempt_successed'] == 2)
    cleaned_df['attempt_3plus_success'] = (cleaned_df['is_successful']) & (cleaned_df['attempt_successed'] >= 3)
    
    # –°–ª–æ–≤–Ω–∏–∫ –¥–ª—è –≥–Ω—É—á–∫–æ–≥–æ –≤–∏–±–æ—Ä—É –ø–µ—Ä—ñ–æ–¥—É –≥—Ä—É–ø—É–≤–∞–Ω–Ω—è
    period_mappers = {
        "day": cleaned_df["date"].dt.to_period("D"),
        "week": cleaned_df["date"].dt.to_period("W"),
        "month": cleaned_df["date"].dt.to_period("M"),
        "quarter": cleaned_df["date"].dt.to_period("Q"),
        "year": cleaned_df["date"].dt.to_period("Y")
    }
    if period not in period_mappers:
        raise ValueError("Used incorrected grouped period. Please use 'day', 'week', 'month', 'quarter' –∞–±–æ 'year'.")
    
    grouper = period_mappers[period]
    # 3. –ê–≥—Ä–µ–≥–∞—Ü—ñ—è –ø–æ–∫–∞–∑–Ω–∏–∫—ñ–≤ –¥–ª—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –∑ "–æ—á–∏—â–µ–Ω–∏—Ö" –¥–∞–Ω–∏—Ö
    sentence_agg = cleaned_df.groupby(grouper).agg(
        # –ü–æ–∫–∞–∑–Ω–∏–∫–∏ –¥–ª—è –ì—Ä–∞—Ñ—ñ–∫—É 1
        total_translations = ("session_id", "count"),
        successful_translations = ('is_successful', 'sum'),
        unsuccessful_translations = ('is_unsuccessful', 'sum'),
        # –ü–æ–∫–∞–∑–Ω–∏–∫–∏ –¥–ª—è –ì—Ä–∞—Ñ—ñ–∫—É 2
        success_on_1st_attempt=('attempt_1_success', 'sum'),
        success_on_2nd_attempt=('attempt_2_success', 'sum'),
        success_on_3plus_attempt=('attempt_3plus_success', 'sum'),
    )


    # 4. –û–∫—Ä–µ–º–æ –∞–≥—Ä–µ–≥—É—î–º–æ —á–∞—Å, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø–æ–¥–≤—ñ–π–Ω–æ–≥–æ –ø—ñ–¥—Ä–∞—Ö—É–Ω–∫—É
    session_unique_df = df.drop_duplicates(subset=['date', 'session_id'])
    session_agg = session_unique_df.groupby(grouper).agg(
        total_time_spent_sec = ('session_duration', 'sum')
    )

    # 5. –û–±'—î–¥–Ω—É—î–º–æ –≤—Å–µ –≤ –æ–¥–Ω—É —Ç–∞–±–ª–∏—Ü—é
    df_grouped = pd.concat([sentence_agg, session_agg], axis=1).fillna(0)

    # 6. –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω—ñ –≤—ñ–¥–Ω–æ—Å–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ (–¥–æ–ª—ñ, —Å–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å)
    df_grouped['total_time_spent_min'] = round(df_grouped['total_time_spent_sec']/ 60, 2)
    df_grouped['avg_min_per_translation'] = df_grouped.apply(
        lambda row: round(row["total_time_spent_min"] / row["total_translations"], 2) if row["total_translations"] > 0 else 0,
        axis=1
    )

    # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –¥–æ–ª–µ–π –¥–ª—è –ì—Ä–∞—Ñ—ñ–∫—É 1
    df_grouped['share_successful'] = df_grouped.apply(
        lambda row: round(row["successful_translations"]/ row["total_translations"] * 100, 1) if row["successful_translations"] > 0 else 0,
        axis=1
    )
    df_grouped['share_unsuccessful'] = 100 - df_grouped['share_successful']

    # –í–∏–¥–∞–ª—è—î–º–æ –Ω–µ–ø–æ—Ç—Ä—ñ–±–Ω–∏–π —Å—Ç–æ–≤–ø–µ—Ü—å
    df_grouped.drop(columns=['total_time_spent_sec'], inplace=True)

    df_grouped.to_excel("grouped_ds.xlsx", index=True)

    return df_grouped


def plot_user_analytics(ax, df, title, chart_type='time_and_success'):
    """
    –ú–∞–ª—é—î –æ–¥–∏–Ω –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–∏–π –≥—Ä–∞—Ñ—ñ–∫ –Ω–∞ –≤–∫–∞–∑–∞–Ω—ñ–π –æ—Å—ñ (ax).

    Args:
        ax (matplotlib.axes.Axes): –í—ñ—Å—å, –Ω–∞ —è–∫—ñ–π –ø–æ—Ç—Ä—ñ–±–Ω–æ –º–∞–ª—é–≤–∞—Ç–∏.
        df (pd.DataFrame): –ê–≥—Ä–µ–≥–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏.
        title (str): –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –≥—Ä–∞—Ñ—ñ–∫–∞.
        chart_type (str): –¢–∏–ø –≥—Ä–∞—Ñ—ñ–∫–∞ ('time_and_success' –∞–±–æ 'attempts').
    """
    # –ì–æ—Ç—É—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –æ—Å—ñ X
    x_labels = df.index.astype(str)
    x = np.arange(len(x_labels)) 

    if chart_type == 'time_and_success':
        # --- –ì—Ä–∞—Ñ—ñ–∫ 1: –î–æ–ª—è —É—Å–ø—ñ—à–Ω–∏—Ö/–Ω–µ—É—Å–ø—ñ—à–Ω–∏—Ö —ñ —á–∞—Å ---

        # –ú–∞–ª—é—î–º–æ —Å—Ç–æ–≤–ø—á–∞—Å—Ç—É –¥—ñ–∞–≥—Ä–∞–º—É
        ax.bar(x, df['successful_translations'], width=0.6, label="Successful(>=80)", color="g")
        ax.bar(x, df['unsuccessful_translations'], width=0.6, bottom=df['successful_translations'], label="Unsuccessful(<80)", color="r")
        ax.set_ylabel("Number of translations")
        ax.legend(loc="upper left")

        # –°—Ç–≤–æ—Ä—é—î–º–æ –¥—Ä—É–≥—É –≤—ñ—Å—å Y –¥–ª—è –≥—Ä–∞—Ñ—ñ–∫–∞ —á–∞—Å—É
        ax2 = ax.twinx()
        ax2.plot(x, df['avg_min_per_translation'], color="b", marker='o', linestyle='--', label= "Average time (min) per each translation")
        ax2.set_ylabel("Minutes", color="b")
        ax2.tick_params(axis="y", labelcolor="b")
        ax2.legend(loc="upper right")
    
    elif chart_type == "attempts":
        # --- –ì—Ä–∞—Ñ—ñ–∫ 2: –ê–Ω–∞–ª—ñ–∑ –∑–∞ —Å–ø—Ä–æ–±–∞–º–∏ ---
        ax.bar(x, df['success_on_1st_attempt'], width=0.6, label="Success from the 1 try", color='#2ca02c')
        ax.bar(x, df['success_on_2nd_attempt'], width=0.6, label="Success from the 2 try", 
                bottom=df['success_on_1st_attempt'],color='#ff7f0e')
        bottom_3 = df['success_on_1st_attempt'] +df['success_on_2nd_attempt']
        ax.bar(x, df['success_on_3plus_attempt'], width=0.6, bottom=bottom_3,
            label='Success from the 3 try', color='#1f77b4')
        bottom_4 = bottom_3 + df['success_on_3plus_attempt']
        ax.bar(x, df['unsuccessful_translations'], width=0.6, bottom=bottom_4,
            label='–ù–µ—É—Å–ø—ñ—à–Ω—ñ', color='#d62728') # —á–µ—Ä–≤–æ–Ω–∏–π
        
        ax.set_ylabel("Number of translations")
        ax.legend(loc="best")

    ax.set_title(title, fontsize=14)
    ax.set_xticks(x)
    ax.set_xticklabels(x_labels, rotation=45, ha="right")
    ax.grid(True,axis="x", linestyle="--", alpha=0.7)
    

async def create_analytics_figure_async(daily_data, weekly_data, user_id):
    """
    Async shell for the creation of the bar-chart
    """
    loop = asyncio.get_running_loop()
    
    fig, axes = plt.subplots(2,1, figsize=(14,12))

    await loop.run_in_executor(
        None,
        plot_user_analytics,
        axes[0],
        daily_data.tail(7),
        "Daily Analytics: Time and Success",
        'time_and_success'
    )

    await loop.run_in_executor(
        None,
        plot_user_analytics,
        axes[1],
        weekly_data.tail(4),
        "Weekly Analytics: Tries",
        "attempts"
    )

            
    # –î–æ–¥–∞—î–º–æ –∑–∞–≥–∞–ª—å–Ω–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    fig.suptitle(f"The whole Analytics for the user {user_id}", fontsize=16)

    # –†–æ–±–∏–º–æ –≤–∏–≥–ª—è–¥ –∫–æ–º–ø–∞–∫—Ç–Ω—ñ—à–∏–º
    plt.tight_layout(rect=[0, 0, 1, 0.96]) # –ó–∞–ª–∏—à–∞—î–º–æ –º—ñ—Å—Ü–µ –¥–ª—è suptitle

    #save in file to send it to telegram
    figure_path = f"analytics_{user_id}.png"
    fig.savefig(figure_path)
    plt.close(fig)

    return figure_path




